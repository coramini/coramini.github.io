---
layout: post
title: "机器学习中的量化"
date: 2024-05-28
author: Cola Liu
categories: [LLM]
---

## 一、什么是量化？
`量化(Quantization)`在不同领域中有不同的含义。在计算机科学和机器学习中，量化通常指的是将连续的数值数据转换为离散的数值数据。这种技术在多个方面都有应用，特别是在深度学习和神经网络模型的优化中。

<img src="/assets/imgs/ai/llm/discrete&continuous.png" />


### 量化的优点
量化通常用于将浮点数转换为低精度的整数值（如8位整数），以减小模型的大小和提高推理速度。量化操作通常有以下的优点 ⬇️

- **1、模型大小减小**
浮点数（如32位浮点数）比整数（如8位整数）占用更多的存储空间。量化后模型的大小可以显著减小。

- **2、计算加速**
整数运算通常比浮点数运算更快，因此量化可以提高模型推理的速度，特别是在资源受限的设备上（如移动设备或嵌入式系统）。

- **3、能效提升**
低精度运算的功耗通常较低，量化后的模型在执行时能效更高。


## 二、量化原理及常用算法

话不多少，直接上图。下图形象直观地展示了量化的过程：

<img src="/assets/imgs/ai/llm/quantization.png" />

- 蓝色实线表示原始的浮点数数据（例如32位浮点数）

- 红色虚线和标记点表示量化后的数据（例如8位整数）

> 通过这种方式，可以看到原始数据的连续波形如何通过量化过程被转换为离散的值。量化过程会将连续的浮点数值映射到有限的几个整数值上，从而减小数据的存储大小和计算复杂度。 ​​


简单来说，量化是将连续的浮点数值转换为离散的整数值的过程。具体算法有多种，下面介绍一种常见的线性量化算法，并通过示例代码展示如何实现这个过程。

### 线性量化算法

线性量化将浮点数值映射到固定范围内的离散整数值。这个过程通常包含以下步骤：

1. **确定量化范围**：
   - 找到浮点数值的最小值和最大值，定义量化的范围。

2. **计算缩放因子和零点**：
   - 缩放因子（scale）用于将浮点数值转换为整数值。
   - 零点（zero point）是整数值的基准点。

3. **量化公式**：
   - 量化后的整数值 \( q \) 通过以下公式计算：
     \[
     q = round(x / scale) + zero\_point
     \]
     其中 \( x \) 是浮点数值。

4. **反量化公式**：
反量化，顾名思义，就是量化的反操作。及把离散的整数值转为精度更高的浮点数。

   - 反量化恢复浮点数值 \( x \)：
     \[
     x = (q - zero\_point) \times scale
     \]


## 三、量化在机器学习中的应用
量化主要在机器学习中的**模型优化和部署阶段**使用。

它作用于已经训练好的**模型参数**，将训练好的模型参数和激活值降为精度较低的整数值，以减少模型大小，加快模型推理速度。

关键代码如下 ⬇️


```python
import torch
import torch.quantization
import torch.nn as nn
import torch.optim as optim
from torchvision.models import resnet18

# 加载预训练的 ResNet18 模型
model = resnet18(pretrained=True)
model.eval()

# 定义量化配置
model.qconfig = torch.quantization.default_qconfig
torch.quantization.prepare(model, inplace=True)

# 对一些示例数据运行模型，以便收集统计信息
dummy_input = torch.randn(1, 3, 224, 224)
model(dummy_input)

# 量化模型
torch.quantization.convert(model, inplace=True)

# 现在模型已经被量化，可以用于推理
output = model(dummy_input)
print(output)

```
