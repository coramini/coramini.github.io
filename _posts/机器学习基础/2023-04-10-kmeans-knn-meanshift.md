---
layout: post
title: "kmeans、knn 和 meanshift"
date: 2023-04-10
author: cora Liu
categories: [机器学习基础]
---

# 聚类算法介绍

## Kmeans & Meanshift & KNN
## 一、Kmeans

> **K均值聚类**，以空间中k个点为中心进行聚类，对最靠近他们的对象归类，是聚类算法中最为基础但也最为重要的算法。

Kmeans属于**机器学习**中的**无监督学习**，即在数据结果没有被标记的情况下，我们对数据进行分类 ⬇️

 <img src="/assets/imgs/ai/聚类/kmeans.png" width="500" />


### 1. Kmeans算法原理

- 选择聚类的个数 **k**
- 确定聚类中心（随机确定或其他）
- 根据点到聚类中心的距离确定各个点所属类别
- 根据各个类别数据更新聚类中心
- 重复以上步骤直到收敛（中心点不再变化）
 <img src="/assets/imgs/ai/聚类/kmeans原理.png" width="800" />

### 2. 优点
- 原理简单、实现容易、收敛速度快
- 参数少，方便使用

### 3. 缺点
- 需要设置k
- 随机选择初始聚类中心，结果可能缺乏一致性


## 二、Meanshift
> **均值漂移聚类**，一种基于密度梯度上升的聚类算法（沿着密度上升的方向寻找聚类中心点）

Meanshift也是**机器学习**中的**无监督学习**，即在数据结果没有被标记的情况下，我们对数据进行分类 ⬇️

 <img src="/assets/imgs/ai/聚类/meanshift.png" width="500" />

### Meanshift算法原理

- 随机选择未被分类的点作为中心点（有若干个）
- 找到离中心点距离在半径之内的点的集合 **S**
- 计算从中心点到集合 S 中每个元素的偏移向量 **M**
- 中心点以向量 **M** 移动
- 重复以上步骤，直到收敛，且所有的点被归类
- 分类：根据每个类，对每个点的访问频率，取访问频率最大的那个类，作为当前点集的所属类


 <img src="/assets/imgs/ai/聚类/meanshift原理.png" width="600" />

 在这个算法中，我们不需要给出刚开始的中心点，但是需要给出计算的半径（有工具可以计算哒！）

  <img src="/assets/imgs/ai/聚类/meanshift半径.png" width="500" />



## 三、KNN

> **K近邻分类模型**，给定一个训练数据集，对新的输入实力，在训练数据集中找到与该实例最邻近的k个实例（即k近邻），这k个实例的多数属于某个类，就把该输入实例归到这个此类中。KNN也是最简单的机器学习算法之一。

KNN 跟上面两种算法的区别是， **KNN** 是监督学习，数据需要事先标记好。放在一起是为了防止与**Kmeans** 混淆了！

 <img src="/assets/imgs/ai/聚类/knn.png" width="500" />


 举个🌰，若选择 k=3, 即离未知输入点（?）有3个近邻——2个三角、1个方块，那么输入点（?）归类为三角。若选择 k = 7，即离未知输入点（?）有7个近邻——3个三角、4个方块，那么输入点（?）归类为方块。


 <img src="/assets/imgs/ai/聚类/knn原理.png" width="500" />

 以上就是对 **Kmeans**、**Meanshift**、**KNN**算法的基本介绍。很多机器学习库（如**sklearn**）中，这些算法都已经封装好了，开箱即用非常方便～
