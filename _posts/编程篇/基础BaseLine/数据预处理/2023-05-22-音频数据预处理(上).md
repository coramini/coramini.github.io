---
layout: post
title: "éŸ³é¢‘æ•°æ®é¢„å¤„ç†(ä¸Š)"
date: 2023-05-22
author: Cola Liu
categories: [ç¼–ç¨‹ç¯‡,BaseLine,æ•°æ®é¢„å¤„ç†,éŸ³é¢‘]
---

## é—®é¢˜åˆ†ç±»

å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œé¦–å…ˆéœ€è¦å¯¹å¾…è§£å†³çš„é—®é¢˜è¿›è¡Œåˆ†ç±»ã€‚é€šè¿‡é—®é¢˜åˆ†ç±»ï¼Œæ‰¾åˆ°åˆé€‚çš„æ•°æ®é¢„å¤„ç†çš„æ–¹æ³•ã€‚

é‚£ä¹ˆï¼Œè·Ÿè¯­éŸ³ç›¸å…³çš„æœºå™¨å­¦ä¹ æ–¹å‘ä¸»è¦æœ‰ä»¥ä¸‹çš„å‡ ç§ï¼š

- è¯­éŸ³ç¿»è¯‘ï¼šæ—¨åœ¨å°†è¯­éŸ³ä¿¡å·è½¬æ¢ä¸ºæ–‡æœ¬ã€‚å®ƒä»¬å¯ä»¥ç”¨äºè¯­éŸ³åŠ©æ‰‹ã€è¯­éŸ³å‘½ä»¤è¯†åˆ«å’Œè¯­éŸ³è½¬å†™ç­‰åº”ç”¨ã€‚ï¼ˆspeech => textï¼‰

- è¯­éŸ³åˆæˆï¼šåˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å°†æ–‡æœ¬è½¬æ¢ä¸ºè‡ªç„¶æµç•…çš„è¯­éŸ³ã€‚å®ƒä»¬å¯ä»¥åº”ç”¨äºè‡ªåŠ¨åŠ©æ‰‹ã€æœ‰å£°è¯»ç‰©å’Œè¯­éŸ³è¾…åŠ©æŠ€æœ¯ç­‰é¢†åŸŸã€‚ (text => speech)

- å£°éŸ³è¯†åˆ«ï¼šè¿™äº›é¡¹ç›®æ—¨åœ¨æ ¹æ®è¯´è¯äººçš„å£°éŸ³ç‰¹å¾å¯¹å…¶è¿›è¡Œèº«ä»½è¯†åˆ«ã€‚å®ƒä»¬å¯ä»¥ç”¨äºè¯­éŸ³è®¤è¯ã€ä¸ªæ€§åŒ–ç”¨æˆ·ä½“éªŒå’Œç”µè¯è¯†åˆ«ç­‰åœºæ™¯ã€‚ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰

- æƒ…æ„Ÿåˆ†æï¼šè¿™äº›é¡¹ç›®æ—¨åœ¨å¯¹ä¸åŒç±»å‹çš„å£°éŸ³è¿›è¡Œåˆ†ç±»å’Œåˆ†æã€‚ä¾‹å¦‚ï¼Œè¯†åˆ«ç¯å¢ƒå£°éŸ³ã€éŸ³ä¹é£æ ¼åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ã€‚ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰

æ¥ä¸‹æ¥ï¼Œä»‹ç»ä¸€ä¸‹ã€å£°éŸ³è¯†åˆ«ã€‘çš„éŸ³é¢‘æ•°æ®å¤„ç†ç®€è¦æµç¨‹ï½

## é—®é¢˜åˆ†æ

å£°éŸ³è¯†åˆ«é—®é¢˜æ˜¯ä¸€ä¸ªå¤šåˆ†ç±»é—®é¢˜ã€‚å±äº `supervised Learning` çš„èŒƒç•´ã€‚
<img src="/assets/imgs/ai/ç›‘ç£å­¦ä¹ .png" />

supervised learning çš„ç‰¹ç‚¹æ˜¯ï¼Œæ¯ä¸€ä¸ª data éƒ½æ‰“ä¸Šäº† labelï¼Œä¹Ÿå°±æ˜¯æ¯ä¸€æ¡æ•°æ®éƒ½åšå¥½äº†æ ‡è®°ï¼Œæ ‡è®°å£°éŸ³æ˜¯å±äºå“ªä¸ªäººçš„ã€‚

é‚£ä¹ˆï¼Œå¯¹äº supervised learningï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ¯ä¸€æ¡æ•°æ®éƒ½å¤„ç†æˆä»¥ä¸‹è¿™ç§æ ¼å¼ï¼š

> data, label

å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆè¡¨æ ¼ä¸­çš„ä¸€è¡Œæ•°æ®ï¼Œåˆ™æœ‰ä¸€åˆ—æ˜¯dataï¼Œå¦ä¸€åˆ—æ˜¯labelã€‚

åŒç†å¯å¾—ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¤šä¸ªæ•°æ®ï¼ˆbatchï¼‰é‚£ä¹ˆå¤„ç†çš„ç›®æ ‡å°±æ˜¯ï¼š

- data1, label1
- data2, label2
- data3, label3
- data4, label4
- ...
- datan, labeln

## data å’Œ label

ä»ä¸Šé¢çš„åˆ†æå¯ä»¥å¾—åˆ°ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ•°æ®å¤„ç†æˆ `ï¼ˆdata, labelï¼‰` æ ¼å¼ã€‚é—®é¢˜æ¥äº†ï¼Œ`data` å’Œ `label` æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

åœ¨éŸ³é¢‘æ•°æ®ä¸­ï¼Œ`data` æ˜¯éŸ³é¢‘æºï¼Œå³è¯»å–éŸ³é¢‘æ–‡ä»¶ä¸­çš„å†…å®¹ã€‚ `label` æ˜¯æ¯ä¸ªspeakerå”¯ä¸€çš„èº«ä»½æ ‡è¯†ï¼Œå¯ä»¥ç”¨idæ¥è¡¨ç¤ºã€‚

## ä¸¾ä¸ªæ —å­ ğŸŒ°

ä¸‹é¢æ˜¯ä¸€ä»½éŸ³é¢‘ptæ–‡ä»¶ â¬‡ï¸

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/dataset.png" />

- uttr-0a0ac1a3b4784aba9f76c1c7e6e920b5.pt
- uttr-0a18eb1376e141be814dc1bea80a39c0.pt
- ...
å°±æ˜¯éŸ³é¢‘çš„ptæ–‡ä»¶ï¼ˆç»è¿‡Pytorché¢„å¤„ç†çš„æ–‡ä»¶ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬è¯»å–å‡ºæ¥ï¼ˆæœ‰å‡ ä¸ªGçš„.ptæ–‡ä»¶ï¼‰ï¼Œè¿™å°±æ˜¯ `data`ã€‚
`label`æœ‰æ—¶å€™æ˜¯åœ¨éŸ³é¢‘ptæ–‡ä»¶å‘½åçš„æ—¶å€™é¡ºä¾¿åšå¥½æ ‡è®°ï¼Œåœ¨è¿™é‡Œå°±ä¸ä¸€æ ·ï¼Œ`label`ä¸éŸ³é¢‘ptæ–‡ä»¶`data`ä¹‹é—´çš„å…³ç³»è®°å½•åœ¨`mapping.json\metadata.json`é‡Œé¢ã€‚å³ç”¨ä¸€ä¸ª`json`æ–‡ä»¶å»ç»´æŠ¤`data`ä¸`label`ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚

æ¥ä¸‹æ¥åˆ†åˆ«æ¥çœ‹çœ‹è¿™å‡ ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼š

### 1ã€mapping.json

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/mapping.png" style="display:block;" />

ä¹Ÿå°±æ˜¯è¯´ï¼Œ`mapping.json` ç»´æŠ¤çš„æ˜¯`speaker`ä¸`id`çš„æ˜ å°„å…³ç³»ã€‚è¿™é‡Œçš„`id`å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„`label`äº†ã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/speaker2id.png" />

### 2ã€metadata.json

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/metadata.png" style="display:block;" />

`metadata.json` ç»´æŠ¤çš„æ˜¯`speaker`ä¸`feature_path`çš„æ˜ å°„å…³ç³»,ä¹Ÿå°±æ˜¯éŸ³é¢‘ptæ–‡ä»¶çš„åœ°å€çš„æ˜ å°„å…³ç³»ã€‚è¯»å– `feature_path` ä¸­çš„æ•°æ®å°±å¯ä»¥å¾—åˆ° `data`ã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/speaker2path.png" style="display:block;" />

### 3ã€è¯»å–éŸ³é¢‘ptæ–‡ä»¶å¹¶è£å‡
æˆ‘ä»¬çŸ¥é“ï¼Œé€šå¸¸ä¸€ä»½éŸ³é¢‘æœ‰é•¿æœ‰çŸ­ï¼Œè¿™æ—¶å€™æˆ‘ä»¬éœ€è¦å¯¹éŸ³é¢‘`mel`è¿›è¡Œå‰ªè¾‘ï¼Œè®©å®ƒä»¬ä¹‹é—´çš„lenä¿æŒä¸€è‡´ã€‚åœ¨è¿™é‡Œæ¯æ®µéŸ³é¢‘æˆªå–128çš„lengthã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/melcut.png" />

æœ€ç»ˆæˆ‘ä»¬åˆ©ç”¨`mapping.json`å’Œ`metadata.json`æŠŠ `mel` å’Œ `id` mapèµ·æ¥ï¼Œä½œä¸º`data`å’Œ`label`

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/mel2id.png" />

## Pytorchå®ç°

```python

import os
import json
import torch
import random
from pathlib import Path
from torch.utils.data import Dataset
from torch.nn.utils.rnn import pad_sequence
 
 
class myDataset(Dataset):
 def __init__(self, data_dir, segment_len=128):
  self.data_dir = data_dir
  self.segment_len = segment_len
 
  # Load the mapping from speaker neme to their corresponding id. 
  mapping_path = Path(data_dir) / "mapping.json"
  mapping = json.load(mapping_path.open())
  self.speaker2id = mapping["speaker2id"]
 
  # Load metadata of training data.
  metadata_path = Path(data_dir) / "metadata.json"
  metadata = json.load(open(metadata_path))["speakers"]
 
  # Get the total number of speaker.
  self.speaker_num = len(metadata.keys())
  self.data = []
  for speaker in metadata.keys():
   for utterances in metadata[speaker]:
    self.data.append([utterances["feature_path"], self.speaker2id[speaker]])
 
 def __len__(self):
   return len(self.data)
 
 def __getitem__(self, index):
  feat_path, speaker = self.data[index]
  # Load preprocessed mel-spectrogram.
  mel = torch.load(os.path.join(self.data_dir, feat_path))

  # Segmemt mel-spectrogram into "segment_len" frames.
  if len(mel) > self.segment_len:
   # Randomly get the starting point of the segment.
   start = random.randint(0, len(mel) - self.segment_len)
   # Get a segment with "segment_len" frames.
   mel = torch.FloatTensor(mel[start:start+self.segment_len])
  else:
   mel = torch.FloatTensor(mel)
  # Turn the speaker id into long for computing loss later.
  speaker = torch.FloatTensor([speaker]).long()
  return mel, speaker
 
 def get_speaker_number(self):
  return self.speaker_num

```
