---
layout: post
title: "éŸ³é¢‘æ•°æ®é¢„å¤„ç†(ä¸‹)"
date: 2023-05-22
author: Cola Liu
categories: [ç¼–ç¨‹ç¯‡,BaseLine,æ•°æ®é¢„å¤„ç†,éŸ³é¢‘]
---


## æ‰¹é‡æ•°æ®å¤„ç†â€”â€”batch

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä» Dataset çš„ `__getitem__` ä¸­è·å–åˆ°çš„æ•°æ®æ˜¯ä¸€ä¸ªä¸€ä¸ªçš„ã€‚

ä¹Ÿå³æ˜¯ä»¥ä¸‹è¿™ç§å½¢å¼ â¬‡ï¸

- data, label
- data, label
- data, label
- ...

åœ¨è¿™é‡Œï¼Œ`data` å’Œ `label` åˆ†åˆ«å¯¹åº”æ˜¯éŸ³é¢‘æ–‡ä»¶ `mel` å’Œ speakerçš„`id`ã€‚

- mel, id
- mel, id
- mel, id
- ...

é‚£ä¹ˆæ‹¿åˆ°å•æ¡æ•°æ®ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œ**æ‰¹é‡å¤„ç†**ã€‚

- é¦–å…ˆï¼ŒæŠŠæ•°æ®ç”¨ `Zip` è¿›è¡Œå¤„ç†ï¼ŒæŠŠ `mel` å’Œ `id` åˆ†åˆ«ä½œä¸ºå•ç‹¬çš„ä¸€åˆ—ã€‚ï¼ˆå¯ä»¥ç†è§£ä¸ºæ”¾åœ¨ä¸€å¼ è¡¨æ ¼ä¸­ï¼Œä¸€åˆ—æ”¾ `mel`ï¼Œä¸€åˆ—æ”¾ `id`ï¼‰

    |  mel | id |
    |--|--|
    |mel1| 1|
    |mel2| 2|
    |mel3| 3|
    |...| ...|

```python
mel, speaker = zip(*batch)
```

- `mel` å¡«å……
ä¹Ÿè®¸ä½ ä¼šé—®ï¼Œæˆ‘ä»¬ä¸Šä¸€èŠ‚ä¸æ˜¯éƒ½å¤„ç†æˆé•¿åº¦128äº†å—ï¼Ÿé‚£è¿™é‡Œåˆæ˜¯å¡«å……ä»€ä¹ˆå‘¢ã€‚è¿™é‡Œå¡«å……çš„æ˜¯melçš„æ·±åº¦ï¼Œè®©æ¯ä¸€æ¡æ•°æ®çš„å¤§å°éƒ½ä¸º[128, 40]ã€‚è¿™é‡Œç”¨åˆ°çš„æ˜¯`pytorch` ä¸­çš„ `padding_squence`æ–¹æ³•ã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/batch_process.png" />

```python
 mel = pad_sequence(mel, batch_first=True, padding_value=-20)
```

## æ•°æ®åˆ†ç¦»

æ‹¿åˆ°å¤„ç†å®Œçš„æ•°æ®åï¼Œé€šå¸¸æˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œåˆ†ç¦»ã€‚æŠŠæ•°æ®é›†åˆ†ä¸º **è®­ç»ƒé›†trainset** å’Œ **éªŒè¯é›†validset**ã€‚

PyTorch ä¸ºæˆ‘ä»¬æä¾›å¥½äº†ä¸€ä¸ªğŸª“å¯ä»¥æŠŠæ•°æ®â€œåŠˆå¼€â€ï¼Œå³ `torch.utils.data` ä¸­çš„`random_split`ã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/random_split.png" />

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å‡è®¾`trainset`å äº†90%ï¼Œ`validset`å 10% â¬‡ï¸

```python
 # Split dataset into training dataset and validation dataset
 trainlen = int(0.9 * len(dataset))
 lengths = [trainlen, len(dataset) - trainlen]
 trainset, validset = random_split(dataset, lengths)
```

## DataLoader

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç”¨`PyTorch` ä¸­çš„ `DataLoader`æ¥åšæ•°æ®æ‰¹é‡å¤„ç†çš„å·¥ä½œã€‚`DataLoader`æ˜¯ä¸€ä¸ªæ•°æ®åŠ è½½ç›¸å…³çš„ç±»ï¼Œæˆ‘ä»¬æŠŠä¸Šé¢çš„ batchæ•°æ®å¤„ç†å‡½æ•°ï¼Œä»¥åŠ `trainset`ã€`validset` ä½œä¸ºå‚æ•°ä¼ å…¥ã€‚

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/dataloader.png" />

```python
 # train_loader
 train_loader = DataLoader(
  trainset,
  batch_size=batch_size,
  shuffle=True,
  drop_last=True,
  num_workers=n_workers,
  pin_memory=True,
  collate_fn=collate_batch,
 )

 # valid_loader
 valid_loader = DataLoader(
  validset,
  batch_size=batch_size,
  num_workers=n_workers,
  drop_last=True,
  pin_memory=True,
  collate_fn=collate_batch,
 )
```

<img src="/assets/imgs/ai/æ•°æ®é¢„å¤„ç†/éŸ³é¢‘/collate_fn.png" style="display:block;"/>



ä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œ æ‰¹é‡å¤„ç†æ•°æ®å‡½æ•°`collate_batch`ï¼Œä½œä¸º`DataLoader`çš„`collate_fn` å‚æ•°ä¼ å…¥ã€‚

æ€»çš„ä»£ç å®ç°å¦‚ä¸‹ â¬‡ï¸

```python
import torch
from torch.utils.data import DataLoader, random_split
from torch.nn.utils.rnn import pad_sequence


def collate_batch(batch):
 # Process features within a batch.
 """Collate a batch of data."""
 mel, speaker = zip(*batch)
 # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.
 mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.
 # mel: (batch size, length, 40)
 return mel, torch.FloatTensor(speaker).long()


def get_dataloader(data_dir, batch_size, n_workers):
 """Generate dataloader"""
 dataset = myDataset(data_dir)
 speaker_num = dataset.get_speaker_number()
 # Split dataset into training dataset and validation dataset
 trainlen = int(0.9 * len(dataset))
 lengths = [trainlen, len(dataset) - trainlen]
 trainset, validset = random_split(dataset, lengths)

 train_loader = DataLoader(
  trainset,
  batch_size=batch_size,
  shuffle=True,
  drop_last=True,
  num_workers=n_workers,
  pin_memory=True,
  collate_fn=collate_batch,
 )
 valid_loader = DataLoader(
  validset,
  batch_size=batch_size,
  num_workers=n_workers,
  drop_last=True,
  pin_memory=True,
  collate_fn=collate_batch,
 )

 return train_loader, valid_loader, speaker_num
```
