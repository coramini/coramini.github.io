---
layout: post
title: "详解深度学习中的模型验证"
date: 2023-06-02
author: Cola Liu
categories: [编程篇,BaseLine,模型训练验证与测试]
---

> 在进行深度学习模型验证的时候，跟模型训练有一些细节上的不同。本文主要介绍在模型验证过程中需要注意的部分。

模型验证过程主要分为：开始验证、验证过程、结束验证。在开始进行模型验证前，先来看看模型的两种模式。

## train和eval模式

在深度学习中，模型通常在两种模式下运行：**train训练模式**和**eval评估模式**。

- **train模式**是指模型处于训练阶段，此时会启用所有的特定于训练的操作，如启用`Batch Normalization`的统计量更新、启用`Dropout`等。

- **eval模式**是指模型处于推理或评估阶段，此时会禁用这些特定于训练的操作，以确保结果的一致性和可靠性。

|model模式   | train|eval|
|--|--|--|
| 适用场景 |模型训练阶段 | 模型验证阶段|
| 说明 | 启用所有的特定于训练的操作，利于模型优化 | 禁用特定于训练的操作，保证结果的一致性和可靠性 |

## 开始验证
在开始进行模型验证时，我们需要将模型切换到**eval模式**。

调用`model.eval()`方法将模型切换到评估模式。在评估模式下，模型会禁用特定于训练的操作，并保持一致的行为。例如，Batch Normalization层将使用训练时计算的统计量，而不是在每个mini-batch上重新计算统计量。

```python
# start
model.eval()

# validate

# end
```

在上面的示例中，通过调用`model.eval()`方法，模型被设置为**eval评估模式**。然后，可以使用输入张量`input`对模型进行前向传播，并获得输出结果`output`。

在**eval评估模式**下，模型的行为将与推理或评估阶段一致，而不会进行特定于训练的操作。



## 验证过程

模型验证过程的关键点，在于保证模型的一致性与稳定性，我们只需要得到验证的结果。模型是训练过程中更新的。

### torch.no_grad()

> 在`PyTorch`中，`torch.no_grad()`是一个上下文管理器（context manager），用于**指定在其内部执行的代码块不进行梯度计算。**

在深度学习中，通常需要对模型进行训练以**更新权重**和**进行梯度下降操作**。但在模型验证的情况下，我们只希望进行**前向传播（forward）**，而不希望计算梯度。

我们只是想使用训练好的模型进行推理或评估，而不需要更新模型的参数。

下面是模型验证过程的示例 ⬇️
```python
for i, batch in enumerate(dataloader):
  # 不进行梯度计算
  with torch.no_grad(): 
   loss, accuracy = model_fn(batch, model, criterion, device)
   running_loss += loss.item() # 计算损失
   running_accuracy += accuracy.item() # 计算准确率
```

在上面的例子中，`torch.no_grad()`包装的代码块中的计算不会对输入进行梯度计算。


## 结束验证
模型结束验证后，我们需要再次把模型切换成`train`模式。恢复原状不是一个必须的选项，但是是一个好习惯！

调用`model.train()`方法将模型切换到训练模式。

```python
# start
model.eval()

# 模型验证
# do something

# end
model.train()

```


## 代码示例
最终整块模型验证代码示例如下：
```python
from tqdm import tqdm
import torch


def valid(dataloader, model, criterion, device): 
 """Validate on validation set."""
    # 开始验证
    model.eval() # 切换到eval模式
    running_loss = 0.0
    running_accuracy = 0.0
    pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc="Valid", unit=" uttr")

    for i, batch in enumerate(dataloader):
        with torch.no_grad(): # 不进行梯度计算
            loss, accuracy = model_fn(batch, model, criterion, device) # 计算损失和准确率
            running_loss += loss.item()
            running_accuracy += accuracy.item()

        #进度条、可视化
        pbar.update(dataloader.batch_size) 
        pbar.set_postfix(
        loss=f"{running_loss / (i+1):.2f}",
        accuracy=f"{running_accuracy / (i+1):.2f}",
        )

    # 结束验证
    pbar.close()
    model.train() # 切换到train模式
    

    return running_accuracy / len(dataloader)
```
在上面代码中，采用`tqdm`将验证过程可视化。

## 小结
本文主要介绍模型验证过程中，如何保证原来训练模型的稳定性与可靠性。主要是通过 `model.eval()`，`torch.no_grad()`来实现的。
