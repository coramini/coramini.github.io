---
layout: post
title: "关于似然与概率"
date: 2023-07-19
author: cora Liu
categories: [数学篇]
usemathjax: true
---

## 写在前面

国外友人这篇对于`likelihood`的文章[Likelihood, Probability, and the Math You Should Know](https://towardsdatascience.com/likelihood-probability-and-the-math-you-should-know-9bf66db5241b)写得非常浅显易懂。在这里简单总结一下（非直译～


`likelihood（似然）`和 `probability（概率）`是在统计学和概率论中比较容易混淆的两个术语，它们之间有一定的练系但是又不能替换使用。在这里，我们用一个例子来详细了解`likelihood（似然）`与`probability（概率）`以及了解它们在机器学习中的作用。

## 概率（probability）
假设我们有一个城市，我们有一份关于该城市中所有房子及其价格的概率密度数据，如下图所示：

<img src="/assets/imgs/ai/likelihood/fig-1.png" />
上图描述的是概率密度曲线，也称为概率分布曲线。横坐标是房子的价格，纵坐标是概率密度。

在自变量的取值范围内，概率密度函数的积分结果为1，也就是曲线下的面积为1。

### 区间概率
如果我们想要取得价格在 `$600K`至`$800K` 范围内房子数量的概率（probability），只需要对`[$600K, $800K]`区间求积分，即求`[$600K, $800K]`区间内曲线的面积。（图中为0.45）

<img src="/assets/imgs/ai/likelihood/fig-2.png" />

## 似然（likelihood）

现在我们对`probability（概率）`有了一定的概念，接下来我们来看看`likelihood（似然）`。

抛开前面所说的概率分布曲线，假设我们并不知道具体的房子概率分布情况，但是手上有`10000`个房子的价格数据。接下来我们的目标就是需要依据这`10000`个房子的价格数据来获取概率分布函数。


<img src="/assets/imgs/ai/likelihood/fig-3.png" />

上图中每一个点表示一个房子。假设房子的分布可以用一个对数正态分布来描述，均值为`13.2`，标准差为`0.4`。

但是上图中的分布只是假设，我们可以用不同的概率密度曲线去描述房子价格的分布，如下图所示 ⬇️

<img src="/assets/imgs/ai/likelihood/fig-4.png" />

那么，哪个分布能够最好地描述实际数据的分布呢? 这就是`likelihood（似然）` 解决的问题。

## 似然（likelihood）的概念
似然函数（Likelihood function）是统计学中的一个概念，用于描述在给定观测数据下，模型参数的可能性。

似然函数的提出是为了解决**参数估计**的问题。

在统计学中，我们经常需要从`观测数据`(observation)中估计`概率模型的参数`。参数估计的目标是找到最合适的参数值，使得模型能够最好地拟合观测数据。

似然函数通常用符号`L`表示，表示参数`θ`给定观测数据`x`的条件下的`条件联合概率分布（conditional joint probability distribution）`，表示为`L(θ|x)`。

在本文的例子中，`θ`表示不止一个参数，它是参数的统称。对于一个对数正态分布来说，参数有均值 `μ` 和 标准差 `σ`。

对于观测数据——房子的价格Price，我们用`y`来表示。那么`似然函数（likelihood）`的式子可以写成 ⬇️

<img src="/assets/imgs/ai/likelihood/e-1.png" />

## 机器学习中的似然函数
在机器学习中，房子价格`Price`可能与其他因素有关，如 房间数量 `num bedrooms`、面积 `sqft`、房龄 `age` 等。

<img src="/assets/imgs/ai/likelihood/fig-5.png" />

假设房子的价格是一个线性回归（linear regression），那么房子价格`Price`可以表示为：

<img src="/assets/imgs/ai/likelihood/e-2.png" />

可以简写为以下的式子。

<img src="/assets/imgs/ai/likelihood/e-3.png" />

其中，`x` 表示房子的其他特征，`y` 是房子的价格，`θ` 该回归模型的参数。`ε`是误差项，表示模型无法完全解释的随机误差。

<img src="/assets/imgs/ai/likelihood/fig-6.png" />

上面我们用一个**线性回归模型**去解释房价与其他影响因子之间的关系，在这个线性回归中，我们可以通过训练使得模型可以最好地拟合（bestfit）房屋数据，换句话说，就是找到一系列参数`θ₀, θ₁, θ₂, ...` 使得`似然函数(likelihood function)`的值最大。用数学公式可以表示如下 ⬇️

<img src="/assets/imgs/ai/likelihood/e-4.png" />

使得似然函数最大的方法叫做 `最大似然估计（Maximum Likelihood Evaluation）`，简写为`MLE`。
我们可以用一个向量`θ`来表示参数`θ₀, θ₁, θ₂, ...`的集合，如下图所示 ⬇️

<img src="/assets/imgs/ai/likelihood/e-5.png" />

因此，上文中的式子可以简写为以下的形式 ⬇️

<img src="/assets/imgs/ai/likelihood/e-6.png" />

## 最大似然估计（Maximum Likelihood Estimation）

回到原来的例子，我们有下面的关系成立 ⬇️

<img src="/assets/imgs/ai/likelihood/e-7.png" />

由于每个房子的价格都是**独立**的，对于**独立事件**的概率计算性质可以得到：

<img src="/assets/imgs/ai/likelihood/e-8.png" />

我们把上述式子简写成下面的式子 ⬇️

<img src="/assets/imgs/ai/likelihood/e-9.png" />

上面我们讨论了，在机器学习中，特征往往有多个，比如 `num bedrooms`、`age`、`sqft`等，所以我们把这些因为加进来如下：
<img src="/assets/imgs/ai/likelihood/e-10.png" />

同样地，我们用一个向量来表示多个`x₁, x₂, ...` ，其中 `1` 可以表示常数项/偏置值部分的系数。

<img src="/assets/imgs/ai/likelihood/e-11.png" />

然后，我们把`x向量`替换一下上述`x₁, x₂, ...`得到下列的式子：

<img src="/assets/imgs/ai/likelihood/e-12.png" />

### 对数
在这里，我们把`L(θ)`函数用对数来处理，可以得到 `log[L(θ)]`:

<img src="/assets/imgs/ai/likelihood/e-13.png" />

上面式子利用了对数的一个重要的性质：乘积的对数等于它们各个部分的对数之和。

然而，我们关心的并不是似然函数最大的值是什么，而是关心似然函数最大时，θ的取值是什么。
因此，我们可以写出下面的式子 ⬇️

<img src="/assets/imgs/ai/likelihood/e-14.png" />

因此，最大似然估计`MLE`中 `θ`的取值最终可以写成 ⬇️

<img src="/assets/imgs/ai/likelihood/e-15.png" />